# 1. Measuring Information

![image-20210304201603504](C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210304201603504.png)

这章主要就是讲了怎么去measure information的，其实也就是那个mit公开课讲的log，但是那个我不明白为什么，但是这个我听明白了哈！虽然说耗时很久，但是我很开心哈！

首先1920年代有一个专门帮人传送数据的人叫Alice，她是可以帮人传送数据，但是怎么收费呢？以什么为单位呢？那时候传送数据的形式是这样子的，比如你要传10个硬币的正反面情况过去，我们知道硬币的正反面情况有两种，正or反，所以那边就问你是正吗？一共要问10次，每次问一个问题，所以总共就是问10个问题，每个问题就像是一个树状一样的，那每个问题就要回答一次也就是传送一次数据。

接下来是传达5个字母，每个字母都有26种情况，然后视频里面计算了下如果传F需要问多少个问题，然后最后我忘了哈，问的问题是比大小哈，而不是问是不是中间那个值的，所以如果还问是不是中间的那个值的话是不是效率会更高点？这个暂且不谈了哈。 你可以想象成一个树，树最后的结果有26个，那**问题的个数就是树的高度**，因此每个字母基本要问`log 26`，所以5个字母就是`5log 26`,其实也就是上面的公式， H代表的是总共要问的问题，也就是总共要回答的问题，每个问题可以看做一个二进制数字，**0表示no，1表示yes**这样子，n表示你要传送的个数，s表示的是你的传送值的范围大小。

~~因此我是这样想的，为什么要这样子做？而不是直接把`123`传过去呢？我们都知道底层是二进制，那这样子传的话直接把123的二进制传过去？看起来有点浪费？所以可能真的是这样穿过去的？我不敢保证啊，我不确定是不是这样子，但如果是这样子的话那就会有很多问题要解决。~~

这个应该就是举个例子罢了，因为这个都是在讨论可能性，所以感觉和随机产生有关？那这样看的话感觉bitlife真的蛮强的。

# 2. Origin of Markov chains

<img src="C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210304203307821.png" alt="image-20210304203307821" style="zoom: 50%;" />

这个用来证明了任何东西都可以有一个ratio的，尽管是dependent的东西，这叫`Markov chains`，好像是机器学习里面的东西

# 3. Information entropy

![image-20210304220819447](C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210304220819447.png)

首先这里是在假设两台机器，每台机器随机产生的字母概率不同

![image-20210305155856792](C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210305155856792.png)

bounces就是questions，我终于懂了为什么要这样子做了，1代表的是A问问题的个数，那总的来说就是算平均问问题的个数

![image-20210305160120958](C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210305160120958.png)

然后算出来了，为什么问题问的越少的carry的信息越少呢？因为问题的个数代表的是树的高度，高度越高，outcome越多。

![image-20210305160104792](C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210305160104792.png)

然后用熵去表示这种情况。

![](C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210305171429453.png)

这个可以懂吧，log2，前面有讲过

![image-20210305171833931](C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210305171833931.png)

但是问题来了，为什么`outcome = 1/p`,这个是我之前不懂的，比如你任意选出一个字母是 1/26,那就有26个outcome，就算你的概率不是平均的比如 1/2,1/4,1/4这样分布的，那1/2就有2个outcome，这里不是指总的outcome，应该指的是产生他的时候有1/2的可能是别的数据，其实也就是算产生1/2数据的bounce而已。所以1/2就问1个问题，1/4就问两个问题。

![image-20210305172541375](C:\Users\zbr\AppData\Roaming\Typora\typora-user-images\image-20210305172541375.png)

md，重新看回来我终于懂了！不容易啊

# 4. 2‘s compliment

我终于明白了溢出到底是什么样了，我不清楚是因为我学的不扎实，学了就忘了。

我一直以为overflow就是出现了不该出现的值，不过也没错，但我不知道怎么去分辨哪些是对的哪些是错的

**出现overflow的情况是你的这几位不能容下他的值了，所以会造成最后符号反的情况！**

Overflow only occurs when two positive numbers(Most Significant Bit = 0) result in a negative number( Most Significant Bit =1).

所以这就是overflow，因为有些你算了超出的位数是可以弃掉的，真的终于懂了，但是头好痛啊

# 5.  variable length of encoding

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210309212916.png" alt="image-20210309212916701" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210309212216.png" alt="image-20210309212216149" style="zoom:67%;" />

今天思考了很久这个Entropy和Expected length 的区别，然后一步步回想，感觉想明白了点东西

1. Entropy基本上算是最准确的，也算是lower bound，而 后者只是实际的情况，还是会有偏差
2. 那为什么是最准确的呢？因为他是直接根据概率来算的，而expected length是根据赋予的encoding算的，这个encoding是参照概率的，但是不会那么准确。

# 6. Huffman's Algorithm

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210309223459.png" alt="image-20210309223458831" style="zoom:67%;" />

没什么，我觉得我是终于一路下来懂了为什么要找最优解的tree，而且算是有了一个规范把，因为前面的tree我们就有好几种摆放的方式，但你得有规矩啊，你得确定好啊，所以用huffman的话算是最优解了

## 2. 改进方法

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210310002319.png" alt="image-20210310002318933" style="zoom:67%;" />

他说这样更接近，但我不知道为什么

# 7. Error detection

## 1. what is parity?

![image-20210310210400920](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210310210401.png)

来啦！ 这里看起来有点乱，但是原理很简单，parity就是一个奇偶校验，可以校验出single bit error

然后你可以设定两种校验，一种是奇校验，另外是一种是偶检验。

实际上就是数1的个数，如果是偶校验，就要凑成偶数个1，奇校验就要凑成奇数个1。

所以上面的,假设是偶校验

`0100` parity bit = 1

`1100` parity bit = 0

## 2. Hamming code

这里解释了下面为什么p1,p2,p3看的是那几个，是有道理的。因为首先p1，p2,p3都是在2^n,这样设定是为了最后能算出那个error的single bit。

p1(2^0),所以也在寻找(2^0),也就是3,5,7，p2(2^1),所以是(3,6,7),p4(2^2),所以是(5,6,7)

![image-20210310214344436](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210310214344.png)

![image-20210310212822403](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210310212822.png)

他首先告诉了我们hamming code一般都是用7位的，你要多少parity bits应该是依据data bits决定的，然后你看下那一列，挺奇怪的，是倒着看的，我目前个人觉得反过来看也不是不行。不过数字塞进去的时候是正着塞进去的，比如 1101(D7D6D5D3)

![image-20210310213650418](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210310213650.png)

有点奇怪还是

所以这里就在计算这7个code应该怎么放

## 3. How to find the error code

![image-20210310215555090](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210310215555.png)

现在假设一个single bit出了问题，那怎么去看是哪个single bit呢？那就要一个个parity去检查，错误的就等于1，对的等于0，最后看下面，加起来就找到了！其实也很容易想把，因为看p4为什么对应那几个值就知道了。然后获得一个唯一值，如果是parity bit错了也是可以看出来的

![image-20210310215848224](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210310215848.png)

终于懂了，最后这里真的是高光时刻，很开心哈哈

![image-20210311181648123](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210311181648.png)

这里讲的是如何check 2个error的时候，我们之前接触到的都是0号位不管的，这时候就可以利用0号位，去检查全体！

## 4. Hamming space

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210311211322.png" alt="image-20210311211321508" style="zoom:67%;" />

说实话，这里给出了一个公式，但是我是真的不理解啊！！！

怎么算hamming distance呢?其实很简单的啦！100 , 110,有1个不一样所以distance是1，看不一样的个数就好了

# 8. Binary

## 1. character sets

![image-20210313155144084](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313155144.png)

这个倒是我不知道的，就是你数字的ascii码会比较容易转成binary码，看最后四位就好了。但是我想的是既然有ascii码帮你安排好了编码，那你huffman又去搞一套自己的编码，那ascii码还有啥用吗？

然后说下其实我对这些都没有真正了解过，所以其实对这方面的知识掌握地挺不熟的。

说一下一共是7个bit，所以有128个，因此hex表示的时候是下面这样子的，7F是最大的

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313155757.png" alt="image-20210313155757105" style="zoom:67%;" />

所以一般1byte就足够所有character了，甚至还有富余，剩了一半，那好像有些电脑就会利用这些空间自己去加一点东西。不同的操作系统是不一样的，ios和windows的就不一样

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313160704.png" alt="image-20210313160704568" style="zoom:50%;" />

1. unicode中对每个可能的character都有对应的编码
2. 会比较好兼容把
3. 但是呢space efficient不咋地，因为unicode变成了32bit，对于只用7bit就可以完成的数字那很多空间是浪费掉的

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313160747.png" alt="image-20210313160747563" style="zoom:50%;" />

然后的话system会confused把，反正就是各种不好，所以虽然想法很好，但是实用性不强

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313160842.png" alt="image-20210313160842140" style="zoom: 50%;" />

这时候就诞生了另外一种编码utf-8，不是固定的bit，有些可以像ascii那样，有些也可以像unicode那样

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313162843.png" alt="image-20210313162842826" style="zoom:50%;" />

我们之前ascii表示A的话是1000001,7 bits,但是这里呢会多加1个，第八位用0表示代表只有1 byte就没了，顺便说下，这里是没有负数的哦，都是unsigned number，如果你想要负数的话那就是字符了

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313163333.png" alt="image-20210313163333647" style="zoom:67%;" />

看吧，不行的

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313164343.png" alt="image-20210313164343259" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313164601.png" alt="image-20210313164601343" style="zoom: 67%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313164724.png" alt="image-20210313164723956" style="zoom: 50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313164815.png" alt="image-20210313164815520" style="zoom:50%;" />

## 2. Fixed Point Binary Fraction

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313193056.png" alt="image-20210313193056186" style="zoom:50%;" />

![image-20210313193437221](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313193437.png)

你要在range和precision做权衡

## 3. Floating point binary Fraction

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313193740.png" alt="image-20210313193740201" style="zoom:50%;" />

尾数英文名叫**mantissa，significand，coefficient**，用于科学计数法中。科学计数法的表示方法为:

**Mantissa x Base^Exponent**

举个例子，123.45用科学计数法可以表示为:

12345 x 10^(-2)

其中12345就是尾数Mantissa，10是基Base，-2是指数Exponent;

同样的，123.45还可以表示为:

1.2345 x 10^(2)

其中1.2345就是尾数Mantissa，10是基Base，2是指数Exponent，这种以10为基，尾数介于1.0到10之间的科学技术表示形式被称为**modified normalized form**;

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313194204.png" alt="image-20210313194204150" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313195510.png" alt="image-20210313195510128" style="zoom:50%;" />

ok,我终于懂什么意思了，这个就是要表示科学计数法像1.0 x 10^3，这样，小数点前面是代表1.0是正的还是负的，exponent的第一位代表的是往左边移还是右边移，是负的还是正的，注意，binary这里的话就不是以10为底了，而是以2，所以的话你看上面结果算出来是3，所以的话是直接在binary里面往右移三个。

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313195808.png" alt="image-20210313195808743" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313200217.png" alt="image-20210313200217397" style="zoom: 50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313200251.png" alt="image-20210313200251488" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210313200436.png" alt="image-20210313200436189" style="zoom:50%;" />

## 4. Floating Point Range Versus Precision

其实range 和precision是反过来的，你只能确保其中的一个。

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210315212020.png" alt="image-20210315212020400" style="zoom: 33%;" />

这里就讲了一个表示的方法，想说明的是有些数是不能被表示出来的，因为精度不够，只能无限接近而已

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210315212040.png" alt="image-20210315212040751" style="zoom:33%;" />

八位，比如拿四位给mantissa，另外四位给exponent，那这个就他最高和最低的范围

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210315212048.png" alt="image-20210315212047901" style="zoom:33%;" />

但是呢，如果你拿五位给mantissa，三位给exponent的话，那你的range大大缩小，但是精度会变高，因为你的精度就是由mantissa决定的

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210315212058.png" alt="image-20210315212058118" style="zoom:33%;" />

## 5. Normalised Floating Point Binary Fractions

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210315213111.png" alt="image-20210315213110927" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210315213340.png" alt="image-20210315213340472" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210315213519.png" alt="image-20210315213519031" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210315214343.png" alt="image-20210315214343329" style="zoom:50%;" />

这个我出了点问题，咋说，我本来是这样写的，0010 0000，这样看起来也可以，但实际上他有一个要求，

### Negative Numbers！

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316201545.png" alt="image-20210316201545051" style="zoom:67%;" />

我一直是搞错了负数的表示了，其实无论是小数点前还是小数点后都用的是补码的形式，所以你看怎么表示-1.5，这个是没有符号位的哈！

![image-20210316201552931](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316201553.png)

注意哈，这里的负数都是2's complement的，注意一下这里的0.01把，因为应该是0.25的，那-0.25 = 1.11，但是你要normalize，所以要摒弃掉很多1，就得到了-0.25的那个，而且注意了，如果是正数，他不会右移两位，而是右移1位就够了，因为头号是可以看出符号的！就奇怪把，他感觉是他早都知道结论了

![image-20210316201557436](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316201557.png)

![image-20210316201601626](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316201601.png)

但是，你看，0.25的表示就有那么多种方法，哪种才是规范的，才是我们想要的

![image-20210316201607455](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316201607.png)

其实就像 1.29 x 10^2,和12.9 x 10^1，表达的都没错，但我们只有一种标准

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316203022.png" alt="image-20210316203022018" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316203226.png" alt="image-20210316203226864" style="zoom:50%;" />

这个是规则？是的哈，基本上就是依照这个规则把，的确也是可以理解的哈，依照上面重复的情况

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316204301.png" alt="image-20210316204301420" style="zoom:50%;" />

这里的等号不是真的等号哈

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316205452.png" alt="image-20210316205451973" style="zoom:50%;" />

其实这个也不难的呀

![image-20210316210637365](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316210637.png)

## 6. Floating Point Binary Addition

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316212006.png" alt="image-20210316212005737" style="zoom:50%;" />

其实这个规则就像我们正常加科学计数法的值一样，要保证exponent一样，然后都是正确的2.3这样的数字，最后加出来的数字超了的话那就再规范化一次吧，但是的话我觉得normalised的话本身就不是很必要，你make exponent same 都不normalised了

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316212835.png" alt="image-20210316212835108" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316213612.png" alt="image-20210316213612037" style="zoom:50%;" />

我想说的一个点是，他这个视频里面我知道大概是为了简化，但是真的很误导人，1010.1开头的话那这个是负数啊！我觉得还是尽量避免把！但看了一眼，好像他们都是这样做的，可能这样也没多大关系把，浮点数这里会体现出来的

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316214649.png" alt="image-20210316214649090" style="zoom: 50%;" />

这里看起来就像是负数啊

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316225457.png" alt="image-20210316225457292" style="zoom: 50%;" />

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210316230825.png" alt="image-20210316230825415" style="zoom:50%;" />

这个补的也要知道呀，你懂把负数 1110.0 = 10.0哈，所以的话你补1是一样的结果

## 7. Floating Number Subtraction

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210317214703.png" alt="image-20210317214702894" style="zoom:50%;" />

## 8. IEEE 754

![image-20210318092112710](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210318092113.png)

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210318092848.png" alt="image-20210318092848582" style="zoom:50%;" />

他这里说最后一步5去掉1的原因是，所有的real number都有这个1都会有，也的确是，所以没必要存起来，反正觉得蛮多规则的吧

![image-20210318094419501](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210318094419.png)

知道为啥要加127了哈，是偏移量哈

![image-20210318094825721](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210318094826.png)

用这种偏移量的话就很容易比大小，直接 比bit by bit 就好了，不需要用2's complement,不能一下看出来的

![image-20210318235143994](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210318235144.png)

太糊了，但没办法，一个是给你看小数怎么转成二进制的，![image-20210318235411430](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210318235411.png)

![image-20210318235423264](https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210318235423.png)

<img src="https://raw.githubusercontent.com/ZhengIvy/Figurebed/main/img/20210318235437.png" alt="image-20210318235437008" style="zoom:50%;" />